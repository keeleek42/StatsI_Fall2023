#####################
# load libraries
# set wd
# clear global .envir
#####################
getwd()
setwd("/Users/sire/Documents/GitHub/StatsI_Fall2023/problemSets/PS01/template")
getwd()
set.seed(42)
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c(),  pkgTest)
#####################
# Problem 1
#####################
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
length(y)
mean.y <- mean(y) #used to calculate the mean IQ of y
print(mean.y) #control
sum_errors <- NULL #creating sum of errors
for(i in 1:length(y))
{sum_errors[i] <- y[i] - mean.y}
sum_errors_simple <- y-mean.y #easy way of the above code
sum_errors_sqrd <- sum_errors^2 #creating the sum squarred error
sum_errors_sqrd #control
variance <- (sum(sum_errors_sqrd))/(length(y)-1) #creating the variance
variance #control
std_devi <- sqrt(variance) #standard deviation
std_devi #control
#CI fÃ¼r n<30 mit t-distribution (qnorm falls n>30)
st_error <- qt(0.950, df = length(y) - 1) * (sd(y) / sqrt(length(y)))
print(st_error)
CI_lower <- mean(y) - st_error
CI_higher <- mean(y) + st_error
print(c(CI_lower, mean(y), CI_higher))
#Solution
print(c(CI_lower, mean(y), CI_higher))
#Solution
print(c(CI_lower, mean(y), CI_higher))
t_stat <- (mean(y)-100)/(sd(y)/sqrt(length(y))) #calculating t statistic
P_value <- pt(t_stat, df = length(y)-1, lower.tail = FALSE)
print(P_value)
t_test <- t.test(y, mu = 100, alternative = 'greater') #control: doing a checkup with t.test function
t_test #gives same p-value
t_test #gives same p-value
t_test <- t.test(y, mu = 100, alternative = 'greater') #control: doing a checkup with t.test function
t_test #gives same p-value
t_stat <- (mean(y)-100)/(sd(y)/sqrt(length(y))) #calculating t statistic
P_value <- pt(t_stat, df = length(y)-1, lower.tail = FALSE)
print(P_value)
t_test <- t.test(y, mu = 100, alternative = 'greater') #control: doing a checkup with t.test function
t_test #gives same p-value
t.test(y)
t.test(y, mu = 100)
t_test #gives same p-value
print(P_value)
t_test #gives same p-value
#####################
# Problem 2.1
#####################
rm(list=ls()) #cleanup for a better overview
set.seed(42) #setting my standard seed
library(tidyverse)
install.packages("ggplot2")
library(ggplot2)
install.packages("ggplot2")
library(GGally) #found after research on https://www.geeksforgeeks.org/how-to-create-and-interpret-pairs-plots-in-r/
expenditure <- read.table("https://raw.githubusercontent.com/ASDS-TCD/StatsI_Fall2023/main/datasets/expenditure.txt", header=T)
View(expenditure) #to get a visual overview of the dataframe
ggpairs(expenditure[,2:5]) + #this is the "cleaner"/"easier" overview that also gives correlations
ggtitle("All plotted against each other with corr.")
#alternative to GGpairs/Ggally-Plot
plot(expenditure$Y, expenditure$X1)
plot(expenditure$Y, expenditure$X2)
plot(expenditure$Y, expenditure$X3)
#and then plot X1 vs X2 and X3 and so on. This is tiresome and would make the latex solution paper too big.
pdf("plot1.pdf")
plot(expenditure$X1, expenditure$Y)
dev.off()
pdf("plot2.pdf")
ggpairs(expenditure[,2:5]) +
ggtitle("All plotted against each other with corr.")
dev.off()
#problem 2.2
pdf("plot3.pdf")
boxplot(Y~Region,data = expenditure, main ="Correlation Expenditures per Capita and Region")
dev.off()
#calculating the mean
for(i in 1:4) #objects of the section of expenditure of region. Of 4 Regions
{
nam <- paste("Region", i, sep = "")
assign(nam, expenditure[expenditure$Region == i,])
}
str(Region1) #looking at the structure of the regions to test and subset afterwards correctly
mean(Region1$Y)  #accessing and calculating the mean of Region 1 Line Y
mean(Region2$Y)
mean(Region3$Y)
mean(Region4$Y)
#could also be done for X1 Income and all other
mean(Region1$X1)
#Problem 2.3
pdf("plot4.pdf")
ggplot(data = expenditure) +
geom_point(mapping = aes(y = Y, x = X1)) +
ggtitle("Y:Expenditure vs. X1:Income per Region")
dev.off()
pdf("plot5.pdf")
ggplot(data = expenditure) +
geom_point(mapping = aes(y = Y, x = X1, colour = as.factor(Region), shape = as.factor(Region))) + #adding the region with different shapes and colors for better distinction.
labs(colour="Region", shape = "Region") +
ggtitle("Y:Expenditure vs. X1:Income per Region")
dev.off()
#Solution 2.3.2
#Solution 2.3.2
#Region 1 (Mean Expenditure: 79.44) is spread the furthest although most of the points are with low income and low expenditure.
#Solution 2.3.2
#Region 1 (Mean Expenditure: 79.44) is spread the furthest although most of the points are with low income and low expenditure.
#Region 2 (Mean Expenditure: 83.91) could be described as the best balanced between income and expenditure
