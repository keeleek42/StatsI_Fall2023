set.seed(42)
#####################
# load libraries
# set wd
# clear global .envir
#####################
getwd()
setwd("/Users/sire/Documents/GitHub/StatsI_Fall2023/problemSets/PS01/template")
getwd()
set.seed(42)
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c(),  pkgTest)
#####################
# Problem 1
#####################
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
length(y)
mean.y <- mean(y) #used to calculate the mean IQ of y
print(mean.y) #control
sd(y)
sum_errors <- NULL #creating sum of errors
for(i in 1:length(y))
{sum_errors[i] <- y[i] - mean.y}
sum_errors_simple <- y-mean.y #easy way of the above code
sum_errors_sqrd <- sum_errors^2 #creating the sum squarred error
sum_errors_sqrd #control
variance <- (sum(sum_errors_sqrd))/(length(y)-1) #creating the variance
variance #control
std_devi <- sqrt(variance) #standard deviation
std_devi #control
#CI for n<30 with t-distribution (qnorm if n>30)
st_error <- qt(0.950, df = length(y) - 1) * (sd(y) / sqrt(length(y)))
print(st_error)
CI_lower <- mean(y) - st_error
CI_higher <- mean(y) + st_error
t_test <- t.test(y)
print(t_test, confidence = 90)
#Solution
print(c(CI_lower, mean(y), CI_higher))
t_test
#Solution
print(c(CI_lower, mean(y), CI_higher))
summary(expenditure)
expenditure <- read.table("https://raw.githubusercontent.com/ASDS-TCD/StatsI_Fall2023/main/datasets/expenditure.txt", header=T)
summary(expenditure)
# load data as vector
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
# capture the number of observations
n <- length(y)
# (a) Calculate the 90% confidence interval for the student IQ
# Step 1: get t-score
t <- qt(0.05, n-1, lower.tail = F)
# Step 2: Calculate lower and upper parts for the 90%
lower_CI <- mean(y)-(t*(sd(y)/sqrt(n)))
upper_CI <- mean(y)+(t*(sd(y)/sqrt(n)))
# print CIs with mean
c(lower_CI, mean(y), upper_CI)
ggpairs(expenditure[,2:5]) + #this is the "cleaner"/"easier" overview that also gives correlations
ggtitle("All plotted against each other with corr.")
library(GGally) #found after research on https://www.geeksforgeeks.org/how-to-create-and-interpret-pairs-plots-in-r/
library(ggplot2)
install.packages("ggplot2")
install.packages("ggplot2")
# (b) Step 1: Calculate the standard error
SE <- sd(y)/sqrt(n)
# Step 2: Calculate the test statistic for this hypothesis testing of mean
t <- (mean(y) - 100)/SE
# Or another way to do this hypothesis testing is to use the function t.test directly
t.test(y, mu = 100, conf.level = 0.95, alternative = "greater")
# read in expenditure data
expenditure <- read.table("https://raw.githubusercontent.com/ASDS-TCD/StatsI_Fall2023/main/datasets/expenditure.txt", header=T)
# inspect data through summary
summary(expenditure)
# generate boxplot with comparisons for different values of Region
pdf("plot_2b.pdf")
pairs(expenditure[,2:5], main = "")
pairs(expenditure[,2:5], main = "")
boxplot(expenditure$Y~expenditure$Region, xlab="Region", ylab="Y", main="")
# read in expenditure data
expenditure <- read.table("https://raw.githubusercontent.com/ASDS-TCD/StatsI_Fall2023/main/datasets/expenditure.txt", header=T)
pairs(expenditure[,2:5], main = "")
boxplot(expenditure$Y~expenditure$Region, xlab="Region", ylab="Y", main="")
